{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnet Model and Training\n",
    "\n",
    "This aim of notebook is to define the siamese model that will be used for the Humpback Whale challenge. It will also run the model to trainin it agains our previously generated training and validation dataset and also create the results agains a test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Module Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Training, Validation and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (31218, 44, 100) (31218, 44, 100) (31218,)\n",
      "Validation set (5510, 44, 100) (5510, 44, 100) (5510,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = '../data/Siamese_dataset.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_X1_dataset = save['train_X1_dataset']\n",
    "    train_X2_dataset = save['train_X2_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_X1_dataset = save['valid_X1_dataset']\n",
    "    valid_X2_dataset = save['valid_X2_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_X1_dataset.shape, train_X2_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_X1_dataset.shape, valid_X2_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Declaration of Global Constants\n",
    "Now we declare all the global constants in hee in orde to have them centralized.\n",
    "This way we can easyly tune our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image parameters\n",
    "NUM_CHANNELS = 1\n",
    "IMAGE_HEIGHT = 44\n",
    "IMAGE_WIDHT = 100\n",
    "\n",
    "#Convnet parameters\n",
    "BETA = 0.005\n",
    "PATCH_1 = 5\n",
    "PATCH_2 = 5\n",
    "DEPTH_1 = 8\n",
    "DEPTH_2 = 15\n",
    "NUM_HIDEN = 1024\n",
    "NUM_LABELS = 1\n",
    "\n",
    "\n",
    "#Training parameters\n",
    "BATCH_SIZE = 128\n",
    "NUM_STEPS = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reformat datasets into a TensorFlow-friendly shape:\n",
    "\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (31218, 44, 100, 1) (31218, 44, 100, 1) (31218, 1)\n",
      "Validation set (5510, 44, 100, 1) (5510, 44, 100, 1) (5510, 1)\n"
     ]
    }
   ],
   "source": [
    "num_labels = 1\n",
    "\n",
    "def reformat(dataset1, dataset2, labels):\n",
    "  dataset1 = dataset1.reshape(\n",
    "    (-1, IMAGE_HEIGHT, IMAGE_WIDHT, NUM_CHANNELS)).astype(np.float32)\n",
    "  dataset2 = dataset2.reshape(\n",
    "    (-1, IMAGE_HEIGHT, IMAGE_WIDHT, NUM_CHANNELS)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset1, dataset2, labels\n",
    "train_X1_dataset, train_X2_dataset, train_labels = reformat(train_X1_dataset, train_X2_dataset, train_labels)\n",
    "valid_X1_dataset, valid_X2_dataset, valid_labels = reformat(valid_X1_dataset, valid_X2_dataset, valid_labels)\n",
    "print('Training set', train_X1_dataset.shape, train_X2_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_X1_dataset.shape, valid_X2_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definition of auxiliar functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Accuracy computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network declaration\n",
    "We will use tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10)\n",
      "(128, 10)\n",
      "(128, 10)\n",
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "siamese_model = tf.Graph()\n",
    "\n",
    "with siamese_model.as_default():\n",
    "\n",
    "  # Input data.\n",
    "    tf_train_X1_dataset = tf.placeholder(\\\n",
    "          tf.float32, shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDHT, NUM_CHANNELS))\n",
    "    tf_train_X2_dataset = tf.placeholder(\\\n",
    "          tf.float32, shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDHT, NUM_CHANNELS))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(BATCH_SIZE, NUM_LABELS))\n",
    "    tf_valid_X1_dataset = tf.constant(valid_X1_dataset)\n",
    "    tf_valid_X2_dataset = tf.constant(valid_X2_dataset)\n",
    "    #tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    weights = {\n",
    "      'layer1': tf.Variable(tf.truncated_normal(\\\n",
    "              [PATCH_1, PATCH_1, NUM_CHANNELS, DEPTH_1], stddev=0.1)),\n",
    "      'layer2': tf.Variable(tf.truncated_normal(\\\n",
    "              [PATCH_2, PATCH_2, DEPTH_1, DEPTH_2], stddev=0.1)),\n",
    "      'layer3': tf.Variable(tf.truncated_normal(\\\n",
    "              [IMAGE_HEIGHT // 4 * IMAGE_WIDHT // 4 * DEPTH_2, NUM_HIDEN], stddev=0.1)),\n",
    "      'layer4': tf.Variable(tf.truncated_normal(\\\n",
    "              [NUM_HIDEN, 10], stddev=0.1))\n",
    "      }\n",
    "    biases = {\n",
    "        'layer1' : tf.Variable(tf.zeros([DEPTH_1])),\n",
    "        'layer2' : tf.Variable(tf.constant(1.0, shape=[DEPTH_2])),\n",
    "        'layer3' : tf.Variable(tf.constant(1.0, shape=[NUM_HIDEN])),\n",
    "        'layer4' : tf.Variable(tf.constant(1.0, shape=[1]))\n",
    "        }\n",
    "  \n",
    "  # Model.\n",
    "    def model(data):\n",
    "        conv = tf.nn.conv2d(data, weights['layer1'], [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + biases['layer1'])\n",
    "        conv = tf.nn.conv2d(hidden, weights['layer2'], [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + biases['layer2'])\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, weights['layer3']) + biases['layer3'])\n",
    "        return tf.matmul(hidden, weights['layer4']) + biases['layer4']\n",
    "    \n",
    "    \n",
    "  # Training computation.\n",
    "    with tf.variable_scope(\"siamese\") as scope:\n",
    "        logits1 = model(tf_train_X1_dataset)\n",
    "        print(logits1.shape)\n",
    "        scope.reuse_variables()\n",
    "        logits2 = model(tf_train_X2_dataset)\n",
    "        print(logits2.shape)\n",
    "        \n",
    "    with tf.variable_scope(\"siamese_val\") as scope:\n",
    "        val_logits1 = model(tf_train_X1_dataset)\n",
    "        print(logits1.shape)\n",
    "        scope.reuse_variables()\n",
    "        val_logits2 = model(tf_train_X2_dataset)\n",
    "        print(logits2.shape)\n",
    "        \n",
    "    def loss(y):\n",
    "        margin = 5.0\n",
    "        labels_t = y\n",
    "        labels_f = tf.subtract(1.0, y, name=\"1-yi\")          # labels_ = !labels;\n",
    "        eucd2 = tf.pow(tf.subtract(logits1, logits2), 2)\n",
    "        eucd2 = tf.reduce_sum(eucd2, 1)\n",
    "        eucd = tf.sqrt(eucd2+1e-6, name=\"eucd\")\n",
    "        C = tf.constant(margin, name=\"C\")\n",
    "        # yi*||CNN(p1i)-CNN(p2i)||^2 + (1-yi)*max(0, C-||CNN(p1i)-CNN(p2i)||^2)\n",
    "        pos = tf.multiply(labels_t, eucd2, name=\"yi_x_eucd2\")\n",
    "        # neg = tf.multiply(labels_f, tf.subtract(0.0,eucd2), name=\"yi_x_eucd2\")\n",
    "        # neg = tf.multiply(labels_f, tf.maximum(0.0, tf.subtract(C,eucd2)), name=\"Nyi_x_C-eucd_xx_2\")\n",
    "        neg = tf.multiply(labels_f, tf.pow(tf.maximum(tf.subtract(C, eucd), 0), 2), name=\"Nyi_x_C-eucd_xx_2\")\n",
    "        losses = tf.add(pos, neg, name=\"losses\")\n",
    "        loss = tf.reduce_mean(losses, name=\"loss\")\n",
    "        return loss\n",
    "        \n",
    "    loss = loss(tf_train_labels)\n",
    "    \n",
    "  # Optimizer.\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "  \n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.reduce_sum(tf.pow(tf.subtract(logits1, logits2), 2),1)\n",
    "    valid_prediction = tf.reduce_sum(tf.pow(tf.subtract(val_logits1, val_logits2), 2),1)\n",
    "    #test_prediction = tf.nn.softmax(model(tf_test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 7.126099\n",
      "Minibatch loss at step 50: 6.438933\n",
      "Minibatch loss at step 100: 6.738636\n",
      "Minibatch loss at step 150: 6.537175\n",
      "Minibatch loss at step 200: 6.644315\n",
      "Minibatch loss at step 250: 6.649497\n",
      "Minibatch loss at step 300: 6.646153\n",
      "Minibatch loss at step 350: 6.545793\n",
      "Minibatch loss at step 400: 6.429983\n",
      "Minibatch loss at step 450: 6.410410\n",
      "Minibatch loss at step 500: 6.616727\n",
      "Minibatch loss at step 550: 6.472067\n",
      "Minibatch loss at step 600: 6.515833\n",
      "Minibatch loss at step 650: 6.305239\n",
      "Minibatch loss at step 700: 6.479825\n",
      "Minibatch loss at step 750: 6.308242\n",
      "Minibatch loss at step 800: 6.319757\n",
      "Minibatch loss at step 850: 6.171739\n",
      "Minibatch loss at step 900: 6.504192\n",
      "Minibatch loss at step 950: 6.317156\n",
      "Minibatch loss at step 1000: 6.413850\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAEKCAYAAACv0An/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XucXXV97//Xey6Zmdxm5zKE3GAm\nkouAScAQQC5R8QKeXxGrVeixCmIpFbH92dNH6ek5tj97fv60nl9bvBSKIF5KoYqXoiKoiCgquQBJ\nIIFAyARyJZNMMoGEZJKZz/ljr4k7OzPJnpm9Zs/e834+HvuRvdf67rU+K5kvfOZ7VURgZmZmZsNX\nVakDMDMzM7Pjc8JmZmZmNsw5YTMzMzMb5pywmZmZmQ1zTtjMzMzMhjknbGZmZmbDnBM2szIn6auS\ndkh6uo/zkvQFSeslrZZ09lDHaFbuXM+s1JywmZW/rwGXHuf8ZcDs5HUdcMsQxGRWab6G65mVkBM2\nszIXEb8E2o9T5N3ANyLrMSAjaerQRGdWGVzPrNRqSh1Af02ePDmam5tLHYal7PHHH98ZEU2ljqNC\nTAc25XzenBzbll9Q0nVkWwcYM2bMG+fNmzckAVppuJ4VleuZ9apY9azsErbm5mZWrFhR6jAsZZJe\nLHUMI1FE3AbcBrBo0aJwXatsrmel4Xo2shSrnrlL1KzybQFm5nyekRwzs+JxPbNUOWEzq3z3AR9K\nZrGdB3RExDHdNGY2KK5nlqqy6xI1s6NJuht4MzBZ0mbgb4FagIi4FbgfeBewHtgPXFOaSM3Kl+uZ\nlZoTNrMyFxFXneB8ADcMUThmFcn1zErNXaJmZmZmw5wTNjMzM7NhzgmbmZmZ2TBX9gnb/s7DfOGh\n51mx8XgLUJuZmZmVr7JP2Gqqqvinnz3Ho+t3ljoUMzMzs1SUfcI2qqaKprF1bN3zWqlDMTMzM0tF\n2SdsANMyDWzrOFDqMMzMzMxSkVrCJmmupJU5r72S/jyvzDxJv5V0UNJ/G+i9pmca2OIWNjMzM6tQ\nqS2cGxHrgIUAkqrJ7qn2vbxi7cAngCsGc6+pjfU89OzLRASSBnMpMzMzs2FnqLpELwFeiIijdqyP\niB0RsRw4NJiLT8s0cOBQN7v3D+oyZmZmZsPSUCVsVwJ3p3XxaZkGAE88MDMzs4qUesImaRRwOfDt\nQVzjOkkrJK1oa2s75vx0J2xmZmZWwYaihe0y4ImIeHmgF4iI2yJiUUQsampqOub81Ew94ITNzMzM\nKtNQJGxXkWJ3KMCkMaMYVVPlpT3MzMysIqU2SxRA0hjg7cCf5By7HiAibpV0MrACGA90J8t+nB4R\ne/t5Hy/tYWZmZhUr1YQtIvYBk/KO3Zrzfjswoxj3mtpY7y5RMzMzq0gVsdMBZGeKbt3jLlEzMzOr\nPBWVsO145QCHurpLHYqZmZlZUVVMwjY9U093wMt73cpmZmZmlaViErapjT1rsTlhMzMzs8pSMQmb\ndzswMzOzSlVBCVuyeG6HEzYzMzOrLBWTsI0eVUNmdK1b2MzMzKziVEzCBjCt0Ut7mJmZWeWprIQt\n0+AWNjMzM6s4FZWwTc94twMzMzOrPBWVsE3NNLD3wGFeOXCo1KGYmZmZFU1FJWw9S3ts6/A4NjMz\nM6scFZWwTe9Z2sPdomZmZlZBKiph824HZmZmVokqKmE7aVwd1VVyC5uZmZlVlIpK2Gqqqzh5vGeK\nmpmZWWVJLWGTNFfSypzXXkl/nldGkr4gab2k1ZLOHux9p2XqvT2VmZmZVZSatC4cEeuAhQCSqoEt\nwPfyil0GzE5e5wK3JH8O2NTGBlZu2jOYS5iZmZkNK0PVJXoJ8EJEvJh3/N3ANyLrMSAjaepgbjQt\n08C2jtfo7o7BXMbMzMxs2BiqhO1K4O5ejk8HNuV83pwcO4qk6yStkLSira3tuDeanqnnUFewc9/B\nwcRrVjYkXSppXTK04KZezp8i6WFJTyZDD95VijjNyp3rmpVS6gmbpFHA5cC3B3qNiLgtIhZFxKKm\npqbjlu1ZPNdLe9hIkAw3+DLZ4QWnA1dJOj2v2P8AvhURZ5H95elfhjZKs/LnumalNhQtbJcBT0TE\ny72c2wLMzPk8Izk2YL9bi80TD2xEWAysj4gNEdEJ3EN2qEGuAMYn7xuBrUMYn1mlcF2zkhqKhO0q\neu8OBbgP+FAyW/Q8oCMitg3mZtMzTthsRClkWMHfAR+UtBm4H7ixr4v1Z/iB2QhTtLrmemYDkWrC\nJmkM8HbguznHrpd0ffLxfmADsB74CvCxwd5zfEMNY0ZVu0vU7HeuAr4WETOAdwHflNRr3e/P8AMz\nO0ZBdc31zAYitWU9ACJiHzAp79itOe8DuKGY95TE1EyDW9hspChkWMG1wKUAEfFbSfXAZGDHkERo\nVhlc16ykKmqngx7TMg1ePNdGiuXAbEktyQSfK8kONcj1EtmldZD0eqAecD+MWf+4rllJVWTCNj3j\n7alsZIiIw8DHgQeBZ8jOUFsj6dOSLk+K/QXwx5JWkR1PenXSum1mBXJds1JLtUu0VKY1NrDz1U4O\nHOqivra61OGYpSoi7ic7HjT32Kdy3q8FLhjquMwqjeualVJFtrBNTWaKbu/wxAMzMzMrfxWZsE3L\n1ANe2sPMzMwqQ0UmbEfWYnMLm5mZmVWAikzYTm50C5uZmZlVjopM2Opqqpk8ts4Jm5mZmVWEikzY\nILu0xxYnbGZmZlYBKjZhm5ZpYJvHsJmZmVkFqNiEbWpjdnsqr1loZmZm5a5iE7ZpmXr2d3bR8dqh\nUodiZmZmNigVm7D1LO3hcWxmZmZW7io2YevZ7WDbHo9jMzMzs/JWsQnbkd0OOtzCZmZmZuWtYhO2\nyWPqGFVd5S5RMzMzK3upJmySMpLulfSspGcknZ93foKk70laLWmZpDOLde+qKjE1U+8uUTMzMyt7\nabew3Qw8EBHzgAXAM3nn/zuwMiLmAx9KyhfN1MZ673ZgZmZmZS+1hE1SI3AxcAdARHRGxJ68YqcD\nP0/OPws0S5pSrBimZRqcsJmZmVnZS7OFrQVoA+6U9KSk2yWNySuzCvh9AEmLgVOBGfkXknSdpBWS\nVrS1tRUcwPRMA9v3HuBwV/eAH8LMzMys1NJM2GqAs4FbIuIsYB9wU16ZzwIZSSuBG4Enga78C0XE\nbRGxKCIWNTU1FRzA1MYGugN2vHJwoM9gZmZmVnI1KV57M7A5IpYmn+8lL2GLiL3ANQCSBLQCG4oV\nwJGlPfa8xrRkXTYzMzOzcpNaC1tEbAc2SZqbHLoEWJtbJplFOir5+FHgl0kSVxTe7cDMzMwqQZot\nbJDt5rwrSco2ANdIuh4gIm4FXg98XVIAa4Bri3nzI7sddHhpDzMzMytfqSZsEbESWJR3+Nac878F\n5qR1/7F1NYyvr/FMUTMzMytrFbvTQQ8v7WFmZmblruITtumZBrZ4twMzMzMrYxWfsE3LNLDNG8Cb\nmZlZGav4hG1qpp49+w+x7+DhUodiZmZmNiAVn7BNPzJT1K1sZmZmVp4qPmGbdmQtNo9jMzMzs/JU\n8Qnb1MbsbgfbPFPUzMzMylTFJ2xTxtdTJby0h5mZmZWtik/YaqurmDK+3l2iZmZmVrYqPmEDL+1h\nZmZm5W1EJGxTG+vdJWpmZmZla0QkbNMzDWztOEB3d5Q6FDMzM7N+GxEJ27RMA52Hu9m1r7PUoZgV\nnaRLJa2TtF7STX2Ueb+ktZLWSPr3oY7RrBK4rlkp1ZQ6gKFwZGmPjtdoGldX4mjMikdSNfBl4O3A\nZmC5pPsiYm1OmdnAXwMXRMRuSSeVJlqz8uW6ZqU2YlrYwEt7WEVaDKyPiA0R0QncA7w7r8wfA1+O\niN0AEbFjiGM0qwSua1ZSqSZskjKS7pX0rKRnJJ2fd75R0g8krUqaj69JI47p3u3AKtd0YFPO583J\nsVxzgDmSfi3pMUmX9nUxSddJWiFpRVtbWwrhmpWtotU11zMbiLRb2G4GHoiIecAC4Jm88zcAayNi\nAfBm4P+XNKrYQWRG19JQW+0WNhupaoDZZOvYVcBXJGV6KxgRt0XEoohY1NTUNIQhmlWEguqa65kN\nRGoJm6RG4GLgDoCI6IyIPXnFAhgnScBYoB04nEIsTM3Uey02q0RbgJk5n2ckx3JtBu6LiEMR0Qo8\nR/Z/KmZWONc1K6k0W9hagDbgTklPSrpd0pi8Ml8CXg9sBZ4C/iwiuvMvVIzm4+mZBneJWiVaDsyW\n1JK0Tl8J3JdX5vtkf+NH0mSy3TYbhjJIswrgumYllWbCVgOcDdwSEWcB+4D8adDvBFYC04CFwJck\njc+/UDGaj6c1NrhL1CpORBwGPg48SHbIwbciYo2kT0u6PCn2ILBL0lrgYeAvI2JXaSI2K0+ua1Zq\naS7rsRnYHBFLk8/3cmzCdg3w2YgIYL2kVmAesKzYwUzN1NP2ykEOHu6irqa62Jc3K5mIuB+4P+/Y\np3LeB/DJ5GVmA+S6ZqWUWgtbRGwHNkmamxy6BFibV+yl5DiSpgBzSan5uGdpj5c7DqZxeTMzM7PU\npL1w7o3AXUl//wbgGknXA0TErcDfA1+T9BQg4K8iYmcagfxuaY/XOGXS6DRuYWZmZpaKVBO2iFgJ\nLMo7fGvO+a3AO9KMoYcXzzUzM7NyNSJ2OoCjt6cyMzMzKycjJmGrr61m0phRXtrDzMzMys6ISdgg\n2y3qLlEzMzMrNyMsYat3wmZmZmZlZ0QlbFOTxXOzS+WYmZmZlYeCEjZJr5NUl7x/s6RP9LV59HA2\nPdPAvs4u9h4o+nalZmZmZqkptIXtO0CXpNOA28hugPvvqUWVEi/tYWZmZuWo0IStO9lH7T3AFyPi\nL4Gp6YWVjqkZL+1hZmZm5afQhO2QpKuADwM/TI7VphNSen6324GX9jAzM7PyUWjCdg1wPvD/RkSr\npBbgm+mFlY6msXVMHDOKh5/dUepQzMzMzApWUMIWEWsj4hMRcbekCcC4iPhcyrEVXVWVuOZNzfz8\n2R2s3bq31OGYmZmZFaTQWaK/kDRe0kTgCeArkv4x3dDS8aHzmxlbV8Mtj7xQ6lDMzMzMClJol2hj\nROwFfh/4RkScC7wtvbDS0zi6lg+edyo/Wr2V1p37Sh2OmZmZ2QkVmrDVSJoKvJ/fTTooW9de2EJt\ndRW3/sKtbGZmZjb8FZqwfRp4EHghIpZLmgU8n15Y6WoaV8eV58zku09u9ppsZmZmNuwVOung2xEx\nPyL+NPm8ISLem25o6frji2cRAV/51YZSh2JmZmZ2XIVOOpgh6XuSdiSv70iaUcD3MpLulfSspGck\nnZ93/i8lrUxeT0vqSiY2pG7GhNFccdZ07l72ErtePTgUtzQzMzMbkEK7RO8E7gOmJa8fJMdO5Gbg\ngYiYBywAnsk9GRGfj4iFEbEQ+GvgkYhoLzT4wbp+yes4eLibO3+9cahuaWZmZtZvhSZsTRFxZ0Qc\nTl5fA5qO9wVJjcDFwB0AEdEZEXuO85WrgLsLjKcoTjtpLJedeTJf/+1G9h44NJS3NjMzMytYoQnb\nLkkflFSdvD4I7DrBd1qANuBOSU9Kul3SmN4KShoNXEp2k/nezl8naYWkFW1tbQWGXJiPvfk0Xjlw\nmH977MWiXtfMzMysWApN2D5CdkmP7cA24H3A1Sf4Tg1wNnBLRJwF7ANu6qPs7wG/7qs7NCJui4hF\nEbGoqem4DXv9dub0RpbMaeKOX7XyWmdXUa9tZmZmVgyFzhJ9MSIuj4imiDgpIq4ATjRLdDOwOSKW\nJp/vJZvA9eZKhrg7NNcNbzmNXfs6+daKTaUKwczMzKxPhbaw9eaTxzsZEduBTZLmJocuAdbml0vG\nui0B/nMQsQzK4paJnNM8gX995AU6D3eXKgwzMzOzXg0mYVMBZW4E7pK0GlgIfEbS9ZKuzynzHuAn\nEVHSfaI+9pbT2NpxgO+v3FLKMMzMzMyOUTOI78YJC0SsBBblHb41r8zXgK8NIo6iePOcJk6fOp5b\nf/EC7z17BtVVheSjZmZmZuk7bgubpFck7e3l9QrZ9dgqhiRueMtpbNi5jwee3l7qcMzMzMyOOG7C\nFhHjImJ8L69xETGY1rlh6dIzT2ZW0xi+/PB6Ik7YgGhmZmY2JAYzhq3iVFeJP13yOtZu28svnivu\nem9mZmZmA+WELc8VZ01neqaBf3l4falDMTMzMwOcsB2jtrqK6y6exfKNu1nWOmTbmpqZmZn1yQlb\nLz5wzkwmjx3Fl93KZmZmZsNAxU0cKIb62mo+cmEL//DAOr7w0PNUV4kDh7rY39nFa4e6eK0z+9p/\nqIsDnV3sP3SYg4e6+eTb53DZG6aWOnwzMzOrMG5h68MHzzuVSWNG8Y8/fY7PP7iOLz28nnuWvcRP\n1rzMihfbad25j47XDlFdJU4aV8+OVw7y3Se96K4NPUmXSlonab2kvvbrRdJ7JYWk/LURzawArmtW\nSm5h68P4+loe/au3cvBwF/W11dTVVCH1vZjun9/zJL/dsGsIIzQDSdXAl4G3k92/d7mk+yJibV65\nccCfAUuPvYqZnYjrmpWaW9iOo2FUNZnRo6ivrT5usgYwf0aGl/ceZHvHgSGKzgyAxcD6iNgQEZ3A\nPcC7eyn398DnAP+Amg2M65qVlBO2IlkwMwPAqs17ShyJjTDTgU05nzcnx46QdDYwMyJ+dKKLSbpO\n0gpJK9ravBahWY6i1TXXMxsIJ2xFcsa08dRUidVO2GwYkVQF/CPwF4WUj4jbImJRRCxqampKNziz\nCtKfuuZ6ZgPhhK1I6murmTNlHKs3d5Q6FBtZtgAzcz7PSI71GAecCfxC0kbgPOA+D4Y26zfXNSsp\nJ2xFtGBmI6s27SnqPqR3LX2RpZ7MYH1bDsyW1CJpFHAlcF/PyYjoiIjJEdEcEc3AY8DlEbGiNOGa\nlS3XNSspJ2xFtGBGhr0HDrNx1/6iXO+1zi7+9j/X8N+/9xTd3d6M3o4VEYeBjwMPAs8A34qINZI+\nLeny0kZnVjlc16zUUl3WQ1IGuJ1sM3EAH4mI3+aVeTPwz0AtsDMilqQZU5rmz8hOPFi9eQ8tk8cM\n+npPvrSbw93BC237+MVzO3jrvCmDvqZVnoi4H7g/79in+ij75qGIyawSua5ZKaXdwnYz8EBEzAMW\nkP2t5IgkofsXss3GZwB/kHI8qZozZSz1tVWs2lSccWxLW9uRoGlcHbf/qrUo1zQzM7Pyk1rCJqkR\nuBi4AyAiOiMifwrlHwLfjYiXkjI70opnKNRUV3HmtMaiLe2xfGM7rz95PNde2MJvXtjFmq2e0GBm\nZjYSpdnC1gK0AXdKelLS7ZLy+wnnABMk/ULS45I+1NuFymnNmvkzMqzZ2sHhru5BXafzcDdPvLSb\nxS0TueqcUxg9qpo7HnUrm5mZ2UiUZsJWA5wN3BIRZwH7gPy912qANwL/BXgn8D8lzcm/UDmtWbNg\nZiMHDnXz3MuvDuo6T23p4MChbha3TKRxdC3vXzSTH6zayst7vXi2mZnZSJNmwrYZ2BwRPfup3Us2\ngcsv82BE7IuIncAvyY51K1u5Ew8GY/nGdgDOaZ4IwEcuaOFwd/CN324c1HXNzMys/KSWsEXEdmCT\npLnJoUuAtXnF/hO4UFKNpNHAueRNTCg3zZNGM76+ZtDj2Ja1tjOraQxN4+oAOGXSaN55+snctfQl\n9nceLkaoZmZmVibSniV6I3CXpNXAQuAzkq6XdD1ARDwDPACsBpYBt0fE0ynHlCpJLJiZGdRM0a7u\nYPnGdhYnrWs9PnpRC3v2H+I7T2zp45tmZmZWiVJdhy0iVgL523Lcmlfm88Dn04xjqM2f0citj2zg\nwKEu6mur+/39ddtf4ZUDh1nccnTC9sZTJ7BgZoavPtrKf118ClVVKlbIZmZmNox5p4MUzJ+Roas7\nBrwMx7LW7FZU+QmbJD56YQutO/fx0LNlvQKKmZmZ9YMTthQsnJmdeDDQbtHlG3czrbGeGRNGH3Pu\nsjNPZnqmgdt/tWFQMZqZmVn5cMKWginj65kyvm5AM0UjgqWt7ce0rvWoqa7i6jc1s7S1nac2eyFd\nMzOzkcAJW0rmz8iwegAJVevOfex89SCLWyb1WeYDi2cytq6GOx51K5uZmdlI4IQtJQtnZtiwcx8d\nrx3q1/d61l9b3DKhzzLj62v5wDkz+eHqbWzreG1QcZqZmdnw54QtJfNnNAL0u9tyaWs7E8eM4nVN\nY49b7uo3NdMdwdd/8+KAYzQzM7Py4IQtJfOnJxMP+jmObVlrdv016fhLdsycOJrLzpzKvy99kX0H\nvZCumZlZJXPClpLG0bU0TxrNqk2FJ2xb97zG5t2vcU4fEw7yXXtRC3sPHObbKzYNNEwzMzMrA07Y\nUrRgZv8mHvSMXzu3wITt7FMmcPYpGb766410dceAYjQzM7PhzwlbiubPyLB97wF27D1QUPmlre2M\nravh9VPHF3yPj140i5fa9/PTtS8PNEwzMzMb5pywpWhBMvFgVYGtbMtb23njqROo7seWU+84fQoz\nJjR4iQ8zM7MK5oQtRWdMa6S6SgWNY9v16kGe3/Fqnwvm9qWmuoqPXNDC8o27WdmP8XJmZmZWPpyw\npahhVDVzpowraKbo8o27gcLHr+V6/zkzGVdXwx2Ptvb7u2ZmZjb8OWFL2YIZjTy1pYOI408KWL6x\nnVE1Vbwh6Ubtj7F1NVx17inc/9Q2tuzxQrpmZmaVxglbyubPyLBn/yFeat9/3HLLWts5a2aGuprq\nAd3nw29qBuB//XAtBw51DegaZmZmNjw5YUvZgpnZFrPjjS975cAh1mztGFB3aI/pmQb+2zvm8uOn\nt/OB2x7zllVmZmYVJNWETVJG0r2SnpX0jKTz886/WVKHpJXJ61NpxlMKc6aMo66m6rjrsT3x0h66\ng4IXzO3Ln775dfzrH72R9S+/wu998VGWtbYP6noDdaLuXzMzM+uftFvYbgYeiIh5wALgmV7K/Coi\nFiavT6ccz5Crra7ijGnjWX2ciQfLWndRXSXOPqXvDd8L9c4zTub7N1zAuPpa/vArj/HN324c0gTq\num+s4BP3rByy+5mZmY0EqSVskhqBi4E7ACKiMyJG5LoT82dkeGpLB4e7uns9v6y1nTOnNzKmrqYo\n95s9ZRzfv+ECLp7TxP/8zzX81XdWD8m4tgOHuvjFujZ+sGprvze9NzMzs76l2cLWArQBd0p6UtLt\nksb0Uu58Sask/VjSGb1dSNJ1klZIWtHW1pZiyOlYODPDgUPdPL/j1WPOHTjUxapNHSxuHnzrWq7G\nhlpu/9AiPvHW0/jWis184LbH2N5R2I4LA/XkS3voTJLSmx96LtV7mZmZjSRpJmw1wNnALRFxFrAP\nuCmvzBPAqRGxAPgi8P3eLhQRt0XEoohY1NTUlGLI6ZifLNXRW7foqk3ZJGdxy6Si37eqSnzyHXO5\n9YPZcW3/1xcfPbJfaRqWtu5Cgj++qIWfPbODp7e4lc3MzKwY0kzYNgObI2Jp8vlesgncERGxNyJe\nTd7fD9RKmpxiTCXRPGkM4+pret2iqieBOqfILWy5Lj2zZ1xbDVfdlt64tmWt7bz+5PHceMlsGhtq\n+eefPV/0e5iZmY1EqSVsEbEd2CRpbnLoEmBtbhlJJ0tS8n5xEs+utGIqlaoqMX9GY69bVC1tbWfu\nlHFkRo9KNYa0x7V1Hu7miZd2s7hlIuPra7n2whZ+9szLbmUzMzMrgrRnid4I3CVpNbAQ+Iyk6yVd\nn5x/H/C0pFXAF4Aro0LXhFgwI8O67a8clSQd7urmiRd393v/0IHKH9f26R+uPfGXCvTUlj0cONTN\nebOyz3L1Bc2Mr6/h5ofcymZmZjZYqSZsEbEyGXs2PyKuiIjdEXFrRNyanP9SRJwREQsi4ryI+E2a\n8ZTS/BkZDncHa7ftPXJs7ba97OvsGrKEDX43ru3yBdP4yZrtdHcXJz9e2trTtZt9lmwr2yx+uvZl\n1mx1K5uZmdlgeKeDIdKz40Fut2jPwrZDmbD1eMu8Jna+2nlUAjkYSze0M/uksUwaW3fk2NUXNDOu\nvoYvuJXNzMxsUJywDZGTx9dz0ri6o3Y8WNrazqmTRjNlfP2Qx3PR7Oxs20eeG/wyKYe7unm8l67d\nxobsWLYH17zM2q3FSQztWJIulbRO0npJ+TOxkfRJSWslrZb0kKRTSxGnWblzXbNScsI2RCQxf0aG\nVcnSHt3dwYqN7SxuHvrWNYDJY+s4c/p4Hlk3+IRt7ba9vHrwMOfOOnZpkmsuaHErW4okVQNfBi4D\nTgeuknR6XrEngUURMZ/sbO1/GNoozcqf65qVmhO2IbRgRiMb2vax98Ah1re9yu79hwa9f+hgLJnT\nxOMv7WbvgUODuk5P125vm9c3NtTykQtaeGDNdp4pUverHWUxsD4iNkREJ3AP8O7cAhHxcETsTz4+\nBswY4hjNKoHrmpWUE7YhNH9mBoCnNnccGaTfW5IzVJbMOYmu7uA363cO6jqPbWin+Thdux+5oIVx\ndW5lS8l0YFPO583Jsb5cC/y4r5PlvquIWYqKVtdcz2wgnLANoQXJjgerNu9heWs7U8bXccrE0SWL\n56xTMoyrqxnUOLbu7mD5xvbjTpxoHF3LNRe28OOn3cpWSpI+CCwCPt9XmXLfVcRsODhRXXM9s4Fw\nwjaEMqNHceqk0azatIdlre2c0zyRZN3gkqitruKC0ybzyLq2Ae988NyOV+h47dAJt9a6Nmll++LP\n3cpWZFuAmTmfZyTHjiLpbcDfAJdHxMEhis2skriuWUk5YRti82dk+NXzO9m+90BJu0N7LJnbxNaO\nA6zvZWP6QizdUFjXbuPoWq6+oJn7n9rOs9vdylZEy4HZklokjQKuBO7LLSDpLOBfyf4PZEcJYjSr\nBK5rVlJO2IbYghmN7O/M7naQxobv/XXxnMEt77GstZ1pjfXMmNBwwrLXXtjC2LoavvjQ+gHdy44V\nEYeBjwMPAs8A34qINZI+LenypNjngbHAtyWtlHRfH5czsz64rlmp1ZQ6gJFmQTLxoLGhltknjS1x\nNDA908Dsk8byyHNtfPSiWf36bkSwtHUXF81uKqhrNzN6FFe/qZkvPbyeT2x/hbknjxto2JYjIu4H\n7s879qmc928b8qDMKpDrmpWrhbzmAAAPLklEQVSSW9iG2BnTxlOl7BZOVVWlG7+Wa8mcJpZuaGd/\n5+F+fW/Dzn3sfLWzXzs19LSyfcFj2czMzArmhG2IjR5Vw/9z+Rnc8JbXlTqUI5bMbaKzq/vIeLRC\nFTp+LdeEMaP48JtO5f6ntvHcy6/0635mZmYjlRO2Evij85s565QJpQ7jiHOaJ1JfW9XvcWzLWncx\neWwdLZPH9Ot7H71wFqNrq70um5mZWYGcsBn1tdWcP2tSvxK27Pi1ds6d1f+lSbKtbM386KltPO9W\nNjMzsxNywmZAdhxb6859vLRr/4kLA5t3v8a2joEvTfLRi2bRUFvNF37uGaNmZmYnkmrCJikj6V5J\nz0p6RtL5fZQ7R9JhSe9LMx7r25K5JwHwyPOFtbL1bK3VnwkHuSaOGcWfv202bzwlM6Dvm5mZjSRp\nL+txM/BARLwvWWjwmH2YJFUDnwN+knIsdhzNk0ZzysTRPLKujT8679QTll+6YReZ0bXMOWngS3Nc\nd/HwmXhhZmY2nKXWwiapEbgYuAMgIjojYk8vRW8EvgN4VegSksSSOU385oWddB7uPmH5ZRvbh9XS\nJGZmZpUszS7RFqANuFPSk5Jul3TUdEJJ04H3ALcc70KSrpO0QtKKtraBb1Rux7dkThP7O7tY8eLx\nl/fY3nGAF3ftHxZba5mZmY0EaSZsNcDZwC0RcRawD7gpr8w/A38VEcdt0omI2yJiUUQsampqSida\n4/zXTaK2WiecLbq0dRcA5w6DrbXMzMxGgjQTts3A5ohYmny+l2wCl2sRcI+kjcD7gH+RdEWKMdlx\njKmr4ZzmiTyy7kQJWztj62o4fdr4IYrMzMxsZEstYYuI7cAmSXOTQ5cAa/PKtEREc0Q0k03oPhYR\n308rJjuxJXOaeHb7K7y890CfZZa1trOoeQLVHr9mZmY2JNJeh+1G4C5Jq4GFwGckXS/p+pTvawN0\n8Zxsl3Nf3aI7Xz3I+h2vujvUzMxsCKW6rEdErCTb7Znr1j7KXp1mLFaYeSeP46RxdTzyXBvvXzTz\nmPPLB7n+mpmZmfWfdzqwo/Qs7/Ho8zs53HXsXJClre3U11bxhumNJYjOzMxsZHLCZsdYMreJjtcO\nsWpzxzHnlra288ZTJzCqxj86ZmZmQ8X/17VjXHjaZKp07Di2jv2HeHb7XhY3e/yamZnZUHLCZsfI\njB7FwpmZYxK25RvbiYBzZ3n8mpmZ2VBywma9WjLnJFZv3kP7vs4jx5ZtbGdUdRULZ3rDdjMzs6Hk\nhM16tWRuExHwq+d/18q2dMMuFs7MUF9bXcLIzMzMRh4nbNarN0xvZMLo2iPdoq8ePMzTW/d6OQ8z\nM7MScMJmvaquEhfNbuKXz+2kuzt4/MXddHWHx6+ZmZmVgBM269OSOU3sfPUgz2zfy7LWXVRXibNP\nmVDqsMzMzEYcJ2zWp4vmTAayy3ssa23nzOmNjKlLdXMMMzMz64UTNuvTSePqOWPaeB5c8zKrNnVw\nnsevmZmZlYQTNjuuJXOaWLVpD51d3Z5wYGZmViJO2Oy4lsxpAkCCRc1O2MzMzErBA5LsuM4+dQJj\n62o4ZeJoGhtqSx2OmZnZiOSEzY6rtrqKv/2905k4ZlSpQzEzMxuxnLDZCf3BopmlDsHMzGxES3UM\nm6SMpHslPSvpGUnn551/t6TVklZKWiHpwjTjMTMzMytHabew3Qw8EBHvkzQKGJ13/iHgvogISfOB\nbwHzUo7JzMzMrKyklrBJagQuBq4GiIhOoDO3TES8mvNxDBBpxWNmZmZWrtLsEm0B2oA7JT0p6XZJ\nY/ILSXqPpGeBHwEf6e1Ckq5LukxXtLW1pRiymZmZ2fCTZsJWA5wN3BIRZwH7gJvyC0XE9yJiHnAF\n8Pe9XSgibouIRRGxqKmpKcWQzczMzIafNBO2zcDmiFiafL6XbALXq4j4JTBL0uQUYzKrOJIulbRO\n0npJx/xSJKlO0n8k55dKah76KM3Kn+ualVJqCVtEbAc2SZqbHLoEWJtbRtJpkpS8PxuoA3alFZNZ\npZFUDXwZuAw4HbhK0ul5xa4FdkfEacA/AZ8b2ijNyp/rmpVa2ltT3QjcJWk1sBD4jKTrJV2fnH8v\n8LSklWQrwgciwhMPzAq3GFgfERuSiT33AO/OK/Nu4OvJ+3uBS3p+UTKzgrmuWUmluqxHRKwEFuUd\nvjXn/Ofo528gjz/++E5JL/ZyajKws99BloeR+GynDnUgZWo6sCnn82bg3L7KRMRhSR3AJHr5e5d0\nHXBd8vGgpKeLHvGJlernvZT1rFT3nnviIpYoWl0b4fWslPcu63pWdjsdRESvsw4krYiI/OSwIvjZ\nbKhExG3AbVC6f5uRdt9S3lvSiqG+p43selbKe5d7PUu7S9TM0rUFyN07bEZyrNcykmqARjxW1Ky/\nXNespJywmZW35cBsSS3JbiJXAvfllbkP+HDy/n3Azz1W1KzfXNespMquS/Q4bit1ACnys1mvknEy\nHwceBKqBr0bEGkmfBlZExH3AHcA3Ja0H2sn+j6YQpfq3GWn3LeW9Xf8KlGJdG4n/9iPtmYtyXzn5\nNzMzMxve3CVqZmZmNsw5YTMzMzMb5so+YTvRViHlQNJGSU9JWtkz/VfSREk/lfR88ueE5LgkfSF5\n3tXJDhHDiqSvStqRu7bQQJ5H0oeT8s9L+nBv97L+G8z2OpL+Ojm+TtI7i3zfT0pam/wcPCTp1Jxz\nXUn9WCkpf6B3Me59taS2nHt8NOfcgH8OC7jvP+Xc8zlJe4rxzL3VwbzzrndDYKTVNdezY84Xt55F\nRNm+yA78fAGYBYwCVgGnlzquATzHRmBy3rF/AG5K3t8EfC55/y7gx4CA84ClpY6/l+e5mOy+sU8P\n9HmAicCG5M8JyfsJpX62cn8VUmeAjwG3Ju+vBP4jeX96Ur4OaEmuU13E+74FGJ28/9Oe+yafX035\nma8GvtTLdwf8c9jf/z6R3Rnmq0V65mPqYN5517uUXyOtrrme9Xq+qPWs3FvYCtkqpFzlbnHydeCK\nnOPfiKzHgIykqaUIsC8R8UuyM6Ry9fd53gn8NCLaI2I38FPg0vSjr3iD2V7n3cA9EXEwIlqB9cn1\ninLfiHg4IvYnHx8ju85VMQzmvxOD+Tns732vAu4u8NrH1UcdzOV6l76RVtdcz45V1HpW7glbb1uF\nTC9RLIMRwE8kPa7sliUAUyJiW/J+OzAleV+uz9zf5ynX5xzuCvl7PWp7HaBne53B/Jv097vXkv3N\ntEe9pBWSHpN0RV9fGuS935t0W9wrqWeB1CF55qRLqgX4ec7hwTzzQGNzvSuekVbXXM8Kj21Az1tJ\n67CVswsjYoukk4CfSno292REhKSKWX+l0p7HikvSB8nuQbwk5/CpSR2ZBfxc0lMR8UIRb/sD4O6I\nOCjpT8i2ery1iNc/kSuBeyOiK+dY2s9sI1wJ6prr2SCUewtbIVuFDHsRsSX5cwfwPbJNvC/3dHUm\nf+5IipfrM/f3ecr1OYe7wWyvM5h/k4K+K+ltwN8Al0fEwZ7jOXVkA/AL4KwC71vQvSNiV879bgfe\n2J+4B3rfHFeS100zyGceaGyud8Uz0uqa61nhsQ3sefs7yG44vci2EG4g28TZM9jwjFLH1c9nGAOM\ny3n/G7J92Z/n6EH6/5C8/y8cPYhxWamfoY/nauboSQf9eh6ygzFbyQ7InJC8n1jq5yr3VyF1BriB\nowdCfyt5fwZHD4TeQOEDoQu571lkBw/Pzjs+AahL3k8Gnqcfk4sKvPfUnPfvAR4b7M9hof99AuaR\nnXikYj1z8r2j6mDeOde7lF8jra65nqVfz0r+Q12ESvEu4Lnkh+9vSh3PAOKflfyArQLW9DwD2XEM\nDyU/QD/r+cdM/uG/nDzvU8CiUj9DL890N7ANOES2b/7agTwP8BGyg23XA9eU+rkq5dVbnQE+TfY3\nbYB64NvJ3/syYFbOd/8m+d464LIi3/dnwMvAyuR1X3L8TcnPxqrkz2tTeOb/L6l/q4CHgXnF+Dk8\n0X2Tz38HfDbve4N65j7q4PXA9cl517sheI20uuZ6lm4989ZUZmZmZsNcuY9hMzMzM6t4TtjMzMzM\nhjknbGZmZmbDnBM2MzMzs2HOCZuZmZnZMOeErReSJklamby2S9qS83lUgde4U9LcE5S5QdJ/LU7U\nvV7/9yXNS+v6ZmZmNjS8rMcJSPo74NWI+N95x0X276+7JIEVQNK/kd2G4/uljsXMzMwGzi1s/SDp\nNElrJd1FdvG/qZJuSzaOXSPpUzllH5W0UFKNpD2SPitplaTfJnuGIul/SfrznPKflbRM0jpJb0qO\nj5H0neS+9yb3WthLbJ9PyqyW9DlJF5FdTPCfkpbBZkmzJT2YbDL/S0lzku/+m6RbkuPPSbosOf4G\nScuT769O9lozMzOzIebN3/tvHvChiFgBIOmmiGhP9oF7WNK9EbE27zuNwCMRcZOkfyS7wvFne7m2\nImKxpMuBT5HdoupGYHtEvFfSAuCJY74kTSGbnJ0RESEpExF7JN1PTgubpIeBj0bEC5IuAL4EvCO5\nzEzgHGA28DNJpwEfA/53RPyHpDqyqzabmZnZEHPC1n8v9CRriaskXUv273IacDqQn7C9FhE/Tt4/\nDlzUx7W/m1OmOXl/IfA5gIhYJWlNL99rB7qBr0j6EfDD/AKSMmT3MvtOtjcXOPrf/1tJ9+46SZvI\nJm6/Af6HpFOB70bE+j7iNjMzsxS5S7T/9vW8kTQb+DPgrRExH3iA7N5w+Tpz3nfRd6J8sIAyx4iI\nQ8Ai4PvAFcCPeikmYGdELMx5nZl7mWMvG98ku0HvQeABSRcXGpOZmZkVjxO2wRkPvALslTQVeGcK\n9/g18H7Ijikj24J3FEnjgPER8UPg/wbOSk69AowDiIjdwDZJ70m+U5V0sfb4A2XNIds9+rykWRGx\nPiJuJttqNz+F5zMzM7MTcJfo4DxBtvvzWeBFsslVsX0R+Iaktcm91gIdeWUage8m48yqgE8mx+8G\n/lXSX5BtebsSuCWZ+ToK+DdgVVJ2C7ACGAtcFxGdkv5Q0lXAIWAr8HcpPJ+ZmZmdgJf1GOaSyQw1\nEXEg6YL9CTA7Ig4X8R5e/sPMzGwYcwvb8DcWeChJ3AT8STGTNTMzMxv+3MJmZmZmNsx50oGZmZnZ\nMOeEzczMzGyYc8JmZmZmNsw5YTMzMzMb5pywmZmZmQ1z/wdvr37yjxcXBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc431de11d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots\n",
    "P_FREQ = 100\n",
    "losses = []\n",
    "accuracies = []\n",
    "rates = []\n",
    "\n",
    "with tf.Session(graph=siamese_model) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(NUM_STEPS):\n",
    "    offset = (step * BATCH_SIZE) % (train_labels.shape[0] - BATCH_SIZE)\n",
    "    batch_data_X1 = train_X1_dataset[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_data_X2 = train_X2_dataset[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE), :]\n",
    "    feed_dict = {tf_train_X1_dataset : batch_data_X1, tf_train_X2_dataset : batch_data_X2, \\\n",
    "                 tf_train_labels : batch_labels}\n",
    "    _, _loss, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if np.isnan(_loss):\n",
    "        print('Model diverged with loss = NaN')\n",
    "        quit()\n",
    "        \n",
    "    #Plot variables\n",
    "    if (step % P_FREQ == 0):\n",
    "       losses.append(_loss)\n",
    "       #accuracies.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "    \n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, _loss))\n",
    "  \n",
    "#print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "# Show the results.\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "plt.subplots_adjust(wspace=.8)\n",
    "fig.set_size_inches(10, 4)\n",
    "ax1.plot(range(0, NUM_STEPS, P_FREQ), losses)\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Training steps\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
